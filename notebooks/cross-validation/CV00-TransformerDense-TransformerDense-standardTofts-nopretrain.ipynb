{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, time\n",
    "# select GPU for training\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# import tensorflow.experimental.numpy as np\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import scipy.io as scio\n",
    "import h5py \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices: tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaowei/workspace/RoQ-DCE-DL-github/notebooks/cross-validation/../../lib/data.py:723: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if phase_id is not 0: #consider post-contrast\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import lib\n",
    "from lib.proc import *\n",
    "from lib.simu import *\n",
    "from lib.commons import *\n",
    "from lib.net import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain\n"
     ]
    }
   ],
   "source": [
    "LENGTH = 130\n",
    "CV_SP = 0\n",
    "reg = 1e-2\n",
    "prefix = \"T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len%s-CV%s-RoQ-XAIFinput-nopretrain\"%(str(LENGTH),str(CV_SP))\n",
    "ISTRAIN = True\n",
    "sample_pattern = 'RES01'\n",
    "# parameters to set\n",
    "DCE_DIM = 360\n",
    "INIT_DIM = 4\n",
    "\n",
    "OUT_DIM = LENGTH\n",
    "IN_DIM = OUT_DIM\n",
    "PK_DIM = 2\n",
    "\n",
    "BATCH_SIZE = 1 # \n",
    "LR_RATE = 1e-3\n",
    "\n",
    "BUFFER_SIZE = 8*BATCH_SIZE  # buffer size for shuffle\n",
    "N_EPOCHS = 200\n",
    "CKPT_PERIOD = 1\n",
    "\n",
    "LAYER_NUM = 4\n",
    "FEATURE_NUM = 64\n",
    "\n",
    "hct=0.4\n",
    "\n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9] 0\n"
     ]
    }
   ],
   "source": [
    "mainfolder = \"/hdd1/chaowei/data/dce/pancreas_syn_purified_linCA_wt_bdTK_VARPRO/\"\n",
    "train_ind,test_ind = get_train_test_index(CV_SP,10)\n",
    "print(train_ind,test_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: HP_0508_z16_pan.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-6-aa8a91984345>:13: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if np.array(h5file['c_ts']).ndim is 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: PS_2216_z36_pan.mat\n",
      "processing: HP_0522_z18_pan.mat\n",
      "processing: PS_2216_z32_pan.mat\n",
      "processing: PD_2084_z23_tum.mat\n",
      "processing: PD_2084_z15_pan.mat\n",
      "processing: PS_2216_z34_pan.mat\n",
      "processing: HP_0522_z16_pan.mat\n",
      "processing: PS_2216_z33_pan.mat\n",
      "processing: HP_0508_z23_pan.mat\n",
      "processing: PD_2084_z21_tum.mat\n",
      "processing: HP_0522_z15_pan.mat\n",
      "processing: PS_2216_z35_pan.mat\n",
      "processing: PD_2127_z18_tum.mat\n",
      "processing: PS_2250_z25_pan.mat\n",
      "processing: HP_1002_z31_pan.mat\n",
      "processing: HP_1002_z34_pan.mat\n",
      "processing: PD_2127_z15_pan.mat\n",
      "processing: PS_2250_z28_pan.mat\n",
      "processing: PD_2127_z19_tum.mat\n",
      "processing: HP_0726_z34_pan.mat\n",
      "processing: HP_1002_z26_pan.mat\n",
      "processing: HP_0726_z33_pan.mat\n",
      "processing: HP_2182_z25_pan.mat\n",
      "processing: PD_2158_z26_pan.mat\n",
      "processing: HP_2182_z27_pan.mat\n",
      "processing: PD_2158_z28_both.mat\n",
      "processing: HP_1009_z26_pan.mat\n",
      "processing: HP_1009_z22_pan.mat\n",
      "processing: HP_2182_z31_pan.mat\n",
      "processing: PS_2255_z24_pan.mat\n",
      "processing: HP_2182_z24_pan.mat\n",
      "processing: HP_2182_z32_pan.mat\n",
      "processing: PS_2255_z29_pan.mat\n",
      "processing: PS_2255_z23_pan.mat\n",
      "processing: HP_2196_z24_pan.mat\n",
      "processing: PD_2166_z26_pan.mat\n",
      "processing: HP_2196_z21_pan.mat\n",
      "processing: HP_2184_z27_pan.mat\n",
      "processing: HP_2196_z23_pan.mat\n",
      "processing: PD_2166_z28_both.mat\n",
      "processing: HP_2184_z31_pan.mat\n",
      "processing: PD_2166_z31_pan.mat\n",
      "processing: PS_2266_z25_pan.mat\n",
      "processing: PS_2266_z23_pan.mat\n",
      "processing: HP_2196_z22_pan.mat\n",
      "processing: HP_2281_z30_pan.mat\n",
      "processing: PS_2300_z20_pan.mat\n",
      "processing: PD_2210_z29_both.mat\n",
      "processing: PS_2300_z28_pan.mat\n",
      "processing: PD_2210_z32_pan.mat\n",
      "processing: HP_2206_z21_pan.mat\n",
      "processing: PD_2174_z30_pan.mat\n",
      "processing: HP_2206_z28_pan.mat\n",
      "processing: PD_2174_z26_both.mat\n",
      "processing: PS_2300_z21_pan.mat\n",
      "processing: HP_2199_z22_pan.mat\n",
      "processing: PD_2174_z27_tum.mat\n",
      "processing: HP_2212_z25_pan.mat\n",
      "processing: PS_2305_z23_pan.mat\n",
      "processing: HP_2213_z29_pan.mat\n",
      "processing: HP_2213_z25_pan.mat\n",
      "processing: PS_2305_z27_pan.mat\n",
      "processing: HP_2212_z22_pan.mat\n",
      "processing: HP_2212_z23_pan.mat\n",
      "processing: PD_2175_z33_pan.mat\n",
      "processing: HP_2213_z26_pan.mat\n",
      "processing: HP_2213_z30_pan.mat\n",
      "processing: HP_2212_z24_pan.mat\n",
      "processing: HP_2213_z24_pan.mat\n",
      "processing: HP_2220_z28_pan.mat\n",
      "processing: PD_2200_z37_both.mat\n",
      "processing: PS_2317_z26_pan.mat\n",
      "processing: HP_2220_z24_pan.mat\n",
      "processing: HP_2227_z25_pan.mat\n",
      "processing: PD_2217_z57_both.mat\n",
      "processing: HP_2220_z26_pan.mat\n",
      "processing: HP_2273_z29_pan.mat\n",
      "processing: PD_2217_z56_both.mat\n",
      "processing: PS_2317_z20_pan.mat\n",
      "processing: PD_2200_z30_pan.mat\n",
      "processing: PS_2317_z27_pan.mat\n",
      "processing: PD_2200_z38_pan.mat\n",
      "processing: PD_2202_z28_both.mat\n",
      "processing: PD_2236_z31_both.mat\n",
      "processing: PD_2236_z30_tum.mat\n",
      "processing: HP_2256_z28_pan.mat\n",
      "processing: HP_2261_z30_pan.mat\n",
      "processing: HP_2261_z25_pan.mat\n",
      "processing: HP_2256_z23_pan.mat\n",
      "processing: PS_2313_z28_pan.mat\n",
      "processing: PS_2313_z23_pan.mat\n",
      "processing: PD_2202_z31_pan.mat\n",
      "processing: HP_2256_z26_pan.mat\n",
      "processing: PD_2237_z28_pan.mat\n",
      "processing: HP_2268_z42_pan.mat\n",
      "processing: PD_2248_z31_tum.mat\n",
      "processing: PD_2237_z32_both.mat\n",
      "processing: HP_2265_z25_pan.mat\n",
      "processing: HP_2263_z34_pan.mat\n",
      "processing: HP_2268_z36_pan.mat\n",
      "processing: HP_2265_z30_pan.mat\n",
      "processing: HP_2268_z39_pan.mat\n",
      "processing: HP_2268_z34_pan.mat\n",
      "processing: PD_2248_z33_pan.mat\n",
      "processing: HP_2263_z31_pan.mat\n",
      "processing: HP_2268_z31_pan.mat\n",
      "Train data loaded. X_train_ts Shape: (58408, 130) X_train_pl Shape: (58408, 130)\n"
     ]
    }
   ],
   "source": [
    "# load as array\n",
    "X_train_ts = np.zeros([0,IN_DIM])\n",
    "Y_train_ts = np.zeros([0,IN_DIM])\n",
    "X_train_pl = np.zeros([0,IN_DIM])\n",
    "Y_train_pl = np.zeros([0,IN_DIM])\n",
    "\n",
    "for j in train_ind:\n",
    "    foldername = os.path.join(mainfolder,str(j))\n",
    "    case_id = os.listdir(foldername)\n",
    "    for i in case_id:\n",
    "        print('processing:',i) \n",
    "        h5file = h5py.File(os.path.join(foldername,i),'r')\n",
    "        if np.array(h5file['c_ts']).ndim is 1:\n",
    "            continue\n",
    "        kv = np.array(h5file['kv'],dtype=np.float32).transpose(1,0)\n",
    "\n",
    "        C_ts =  np.concatenate((np.array(h5file['c_ts'],dtype=np.float32).transpose(1,0),\n",
    "                                np.array(h5file['c_bds'],dtype=np.float32).transpose(1,0)),axis=0)\n",
    "        C_ts_lbl=C_ts\n",
    "        \n",
    "        C_bd =  np.mean(np.array(h5file['c_pl_ori'],dtype=np.float32).transpose(1,0),axis=0,keepdims=True)\n",
    "        C_bd_lbl =  C_bd\n",
    "        norm_constant = np.max(C_bd_lbl)*(1-hct)\n",
    "\n",
    "        # generate downsampled R1\n",
    "        C_ts_ds,C_ts,bundle = gen_ds_R1(C_ts,INIT_DIM,C_bd_lbl,OUT_DIM=OUT_DIM,sample_pattern=sample_pattern,average=False)\n",
    "        # generate blood input \n",
    "        C_bd_ds,C_bd,bundle = gen_ds_R1(C_bd,INIT_DIM,C_bd_lbl,OUT_DIM=OUT_DIM,sample_pattern=sample_pattern,average=False)\n",
    "        # clip label \n",
    "        _,C_ts_lbl,_ = gen_ds_R1(C_ts_lbl,INIT_DIM,C_bd_lbl,OUT_DIM=OUT_DIM,sample_pattern=sample_pattern,average=False)\n",
    "        _,C_bd_lbl,_ = gen_ds_R1(C_bd_lbl,INIT_DIM,C_bd_lbl,OUT_DIM=OUT_DIM,sample_pattern=sample_pattern,average=False)\n",
    "        # generate spike\n",
    "        C_ts_itnpl = gen_inge_spike(C_ts_ds,bundle)\n",
    "        C_bd_itnpl = gen_inge_spike(C_bd_ds,bundle)\n",
    "\n",
    "        bd_temp = np.repeat(C_bd_itnpl.reshape([-1,OUT_DIM]),C_ts.shape[0],axis=0)\n",
    "        bd_temp2 = np.repeat(C_bd.reshape([-1,OUT_DIM]),C_ts.shape[0],axis=0)\n",
    "    \n",
    "        X_train_ts = np.append(X_train_ts,C_ts_itnpl/norm_constant,axis=0)\n",
    "        X_train_pl = np.append(X_train_pl,bd_temp/norm_constant,axis=0)\n",
    "        Y_train_ts = np.append(Y_train_ts,C_ts/norm_constant,axis=0)\n",
    "        Y_train_pl = np.append(Y_train_pl,bd_temp2/norm_constant,axis=0)\n",
    "        h5file.close()\n",
    "        \n",
    "print('Train data loaded. X_train_ts Shape:',X_train_ts.shape,'X_train_pl Shape:',X_train_ts.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: HP_0504_z21_pan.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-7-ef2d7de623a9>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if np.array(h5file['c_ts']).ndim is 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: HP_2245_z25_pan.mat\n",
      "processing: PD_0205_z19_pan.mat\n",
      "processing: HP_0504_z18_pan.mat\n",
      "processing: PS_2204_z19_pan.mat\n",
      "processing: PD_0205_z33_both.mat\n",
      "processing: PS_2204_z23_pan.mat\n",
      "processing: PS_2204_z26_pan.mat\n",
      "processing: PS_2204_z24_pan.mat\n",
      "processing: HP_2245_z29_pan.mat\n",
      "processing: HP_0504_z22_pan.mat\n",
      "Validation data loaded. X_valid_ts Shape: (9320, 130)\n"
     ]
    }
   ],
   "source": [
    "# load as array\n",
    "X_valid_ts = np.zeros([0,IN_DIM])\n",
    "Y_valid_ts = np.zeros([0,IN_DIM])\n",
    "X_valid_pl = np.zeros([0,IN_DIM])\n",
    "Y_valid_pl = np.zeros([0,IN_DIM])\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "for j in range(test_ind,test_ind+1):\n",
    "    foldername = os.path.join(mainfolder,str(j))\n",
    "    case_id = os.listdir(foldername)\n",
    "    for i in case_id:\n",
    "        print('processing:',os.path.join(i)) \n",
    "        h5file = h5py.File(os.path.join(foldername,i),'r')\n",
    "        if np.array(h5file['c_ts']).ndim is 1:\n",
    "            continue\n",
    "        kv = np.array(h5file['kv'],dtype=np.float32).transpose(1,0)\n",
    "\n",
    "        C_ts =  np.concatenate((np.array(h5file['c_ts'],dtype=np.float32).transpose(1,0),\n",
    "                                np.array(h5file['c_bds'],dtype=np.float32).transpose(1,0)),axis=0)\n",
    "        C_ts_lbl=C_ts\n",
    "        \n",
    "        C_bd =  np.mean(np.array(h5file['c_pl_ori'],dtype=np.float32).transpose(1,0),axis=0,keepdims=True)\n",
    "        C_bd_lbl =  C_bd\n",
    "        norm_constant = np.max(C_bd_lbl)*(1-hct)\n",
    "\n",
    "        # generate downsampled R1\n",
    "        C_ts_ds,C_ts,bundle = gen_ds_R1(C_ts,INIT_DIM,C_bd_lbl,OUT_DIM=OUT_DIM,sample_pattern=sample_pattern,average=False)\n",
    "        # generate blood input \n",
    "        C_bd_ds,C_bd,bundle = gen_ds_R1(C_bd,INIT_DIM,C_bd_lbl,OUT_DIM=OUT_DIM,sample_pattern=sample_pattern,average=False)\n",
    "        # clip label \n",
    "        _,C_ts_lbl,_ = gen_ds_R1(C_ts_lbl,INIT_DIM,C_bd_lbl,OUT_DIM=OUT_DIM,sample_pattern=sample_pattern,average=False)\n",
    "        _,C_bd_lbl,_ = gen_ds_R1(C_bd_lbl,INIT_DIM,C_bd_lbl,OUT_DIM=OUT_DIM,sample_pattern=sample_pattern,average=False)\n",
    "        # generate spike\n",
    "        C_ts_itnpl = gen_inge_spike(C_ts_ds,bundle)\n",
    "        C_bd_itnpl = gen_inge_spike(C_bd_ds,bundle)\n",
    "\n",
    "        bd_temp = np.repeat(C_bd_itnpl.reshape([-1,OUT_DIM]),C_ts.shape[0],axis=0)\n",
    "        bd_temp2 = np.repeat(C_bd.reshape([-1,OUT_DIM]),C_ts.shape[0],axis=0)\n",
    "    \n",
    "        X_valid_ts = np.append(X_valid_ts,C_ts_itnpl/norm_constant,axis=0)\n",
    "        Y_valid_ts = np.append(Y_valid_ts,C_ts/norm_constant,axis=0)\n",
    "        X_valid_pl = np.append(X_valid_pl,bd_temp/norm_constant,axis=0)\n",
    "        Y_valid_pl = np.append(Y_valid_pl,bd_temp2/norm_constant,axis=0)\n",
    "        h5file.close()\n",
    "        \n",
    "print('Validation data loaded. X_valid_ts Shape:',X_valid_ts.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_series():\n",
    "    for __x, __y in  zip(X_train_ts, Y_train_ts):\n",
    "        yield {\"tissue_ds\":__x}, {\"Tissue\":__y}\n",
    "def gen_series_mul_inputs():\n",
    "    for __x, __x2, __y in  zip(X_train_ts, X_train_pl, Y_train_ts):\n",
    "        yield {\"tissue_ds\":__x, \"aorta_fs\":__x2}, {\"Tissue\":__y}\n",
    "def gen_series_mul_inputs_mul_outputs():\n",
    "    for __x, __x2, __y, __y2 in  zip(X_train_ts, X_train_pl, Y_train_ts, Y_train_pl):\n",
    "        yield {\"tissue_ds\":__x, \"aorta_fs\":__x2}, {\"Tissue\":__y,\"AIF\":__y2}  \n",
    "def gen_series_mul_inputs_3_outputs():\n",
    "    for __x, __x2, __y, __y2, __y3 in  zip(X_train_ts, X_train_bd, Y_train_ts, Y_train_bd,Y_train):\n",
    "        yield {\"tissue_ds\":__x, \"aorta_fs\":__x2}, {\"Tissue\":__y,\"AIF\":__y2,\"kv\":__y3}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct simulation dataset\n",
    "train_ds = tf.data.Dataset.from_generator(gen_series_mul_inputs_mul_outputs,output_types=({\"tissue_ds\":tf.float32,\"aorta_fs\":tf.float32},\n",
    "                                                                              {\"Tissue\":tf.float32,\"AIF\":tf.float32}),\n",
    "                                          output_shapes=({\"tissue_ds\":(IN_DIM),\"aorta_fs\":(IN_DIM)}, {\"Tissue\":(IN_DIM),\"AIF\":(IN_DIM)}))\n",
    "\n",
    "train_ds = (\n",
    "    train_ds\n",
    "    .shuffle(X_train_ts.shape[0])\n",
    "    .repeat()\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices(({\"tissue_ds\":X_valid_ts,\"aorta_fs\":X_valid_pl},\n",
    "                                               {\"Tissue\":Y_valid_ts,\"AIF\":Y_valid_pl}))\n",
    "valid_ds = valid_ds.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# number of steps per epoch\n",
    "N_STEPS = np.ceil(Y_train_ts.shape[0]/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "tissue_ds (InputLayer)          [(None, 130)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aorta_fs (InputLayer)           [(None, 130)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 130)          17030       tissue_ds[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 130)          17030       aorta_fs[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 130)          17030       dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 130)          17030       dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Tissue (Dense)                  (None, 130)          17030       dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "AIF (Dense)                     (None, 130)          17030       dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.greater_1 (TFOpLambda)  (None, 130)          0           tissue_ds[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.boolean_mask_3 (Sl (None,)              0           tissue_ds[0][0]                  \n",
      "                                                                 tf.math.greater_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.boolean_mask_2 (Sl (None,)              0           Tissue[0][0]                     \n",
      "                                                                 tf.math.greater_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 1)         0           tf.compat.v1.boolean_mask_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1)         0           tf.compat.v1.boolean_mask_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, 1, 1)         0           reshape_3[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_1 (TFOpLambda)          (None, 130)          0           tf.math.greater_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.square_1 (TFOpLambda)   (None, 1, 1)         0           tf.math.subtract_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_2 (TFOpLambd ()                   0           tf.cast_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_3 (TFOpLambd ()                   0           tf.math.square_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam ()                   0           tf.math.reduce_sum_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_1 (TFOpLambda)  ()                   0           tf.math.reduce_sum_3[0][0]       \n",
      "                                                                 tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) ()                   0           tf.math.truediv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_loss_1 (AddLoss)            ()                   0           tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.greater_2 (TFOpLambda)  (None, 130)          0           aorta_fs[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.boolean_mask_5 (Sl (None,)              0           aorta_fs[0][0]                   \n",
      "                                                                 tf.math.greater_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.boolean_mask_4 (Sl (None,)              0           AIF[0][0]                        \n",
      "                                                                 tf.math.greater_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 1)         0           tf.compat.v1.boolean_mask_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 1)         0           tf.compat.v1.boolean_mask_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_2 (TFOpLambda) (None, 1, 1)         0           reshape_5[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_2 (TFOpLambda)          (None, 130)          0           tf.math.greater_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.square_2 (TFOpLambda)   (None, 1, 1)         0           tf.math.subtract_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_4 (TFOpLambd ()                   0           tf.cast_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_5 (TFOpLambd ()                   0           tf.math.square_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam ()                   0           tf.math.reduce_sum_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_2 (TFOpLambda)  ()                   0           tf.math.reduce_sum_5[0][0]       \n",
      "                                                                 tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) ()                   0           tf.math.truediv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_loss_2 (AddLoss)            ()                   0           tf.math.multiply_2[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 102,180\n",
      "Trainable params: 102,180\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ----------- construct model -----------\n",
    "import datetime\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "tis_inp = tf.keras.Input(shape=(IN_DIM), name=\"tissue_ds\")\n",
    "bd_inp = tf.keras.Input(shape=(IN_DIM), name=\"aorta_fs\")\n",
    "\n",
    "with tf.name_scope(\"upsample\"):\n",
    "    x2 = tf.keras.layers.Dense(units=IN_DIM)(tis_inp)\n",
    "    x2 = tf.keras.layers.Dense(units=IN_DIM,activation='relu')(x2)\n",
    "    f_ts = tf.keras.layers.Dense(units=IN_DIM,name=\"Tissue\",activation='relu')(x2)\n",
    "with tf.name_scope(\"upsample2\"):\n",
    "    x3 = tf.keras.layers.Dense(units=IN_DIM)(bd_inp)\n",
    "    x3 = tf.keras.layers.Dense(units=IN_DIM,activation='relu')(x3)\n",
    "    f_bd = tf.keras.layers.Dense(units=IN_DIM,name=\"AIF\",activation='relu')(x3)\n",
    "    \n",
    "    \n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=[tis_inp,bd_inp], outputs=[f_ts,f_bd]\n",
    ")\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = LR_RATE),loss=tf.keras.losses.MeanSquaredError())\n",
    "model.add_loss(DCloss_mag(f_ts, tis_inp,reg=0.1))\n",
    "model.add_loss(DCloss_mag(f_bd, bd_inp,reg=0.1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/200\n",
      "58408/58408 [==============================] - 434s 7ms/step - loss: 0.3933 - Tissue_loss: 0.0078 - AIF_loss: 0.3299 - val_loss: 0.1067 - val_Tissue_loss: 0.0027 - val_AIF_loss: 0.1033\n",
      "\n",
      "Epoch 00001: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0001.ckpt\n",
      "Epoch 2/200\n",
      "58408/58408 [==============================] - 425s 7ms/step - loss: 0.0977 - Tissue_loss: 0.0035 - AIF_loss: 0.0942 - val_loss: 0.0634 - val_Tissue_loss: 0.0031 - val_AIF_loss: 0.0585\n",
      "\n",
      "Epoch 00002: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0002.ckpt\n",
      "Epoch 3/200\n",
      "58408/58408 [==============================] - 269s 5ms/step - loss: 0.0534 - Tissue_loss: 0.0035 - AIF_loss: 0.0498 - val_loss: 0.0441 - val_Tissue_loss: 0.0028 - val_AIF_loss: 0.0410\n",
      "\n",
      "Epoch 00003: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0003.ckpt\n",
      "Epoch 4/200\n",
      "58408/58408 [==============================] - 268s 5ms/step - loss: 0.0294 - Tissue_loss: 0.0034 - AIF_loss: 0.0259 - val_loss: 0.0318 - val_Tissue_loss: 0.0023 - val_AIF_loss: 0.0285\n",
      "\n",
      "Epoch 00004: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0004.ckpt\n",
      "Epoch 5/200\n",
      "58408/58408 [==============================] - 269s 5ms/step - loss: 0.0087 - Tissue_loss: 0.0023 - AIF_loss: 0.0064 - val_loss: 0.0294 - val_Tissue_loss: 0.0021 - val_AIF_loss: 0.0261\n",
      "\n",
      "Epoch 00005: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0005.ckpt\n",
      "Epoch 6/200\n",
      "58408/58408 [==============================] - 269s 5ms/step - loss: 0.0083 - Tissue_loss: 0.0022 - AIF_loss: 0.0061 - val_loss: 0.0235 - val_Tissue_loss: 0.0023 - val_AIF_loss: 0.0204\n",
      "\n",
      "Epoch 00006: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0006.ckpt\n",
      "Epoch 7/200\n",
      "58408/58408 [==============================] - 269s 5ms/step - loss: 0.0083 - Tissue_loss: 0.0022 - AIF_loss: 0.0061 - val_loss: 0.0313 - val_Tissue_loss: 0.0024 - val_AIF_loss: 0.0287\n",
      "\n",
      "Epoch 00007: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0007.ckpt\n",
      "Epoch 8/200\n",
      "58408/58408 [==============================] - 268s 5ms/step - loss: 0.0083 - Tissue_loss: 0.0022 - AIF_loss: 0.0060 - val_loss: 0.0221 - val_Tissue_loss: 0.0024 - val_AIF_loss: 0.0194\n",
      "\n",
      "Epoch 00008: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0008.ckpt\n",
      "Epoch 9/200\n",
      "58408/58408 [==============================] - 271s 5ms/step - loss: 0.0077 - Tissue_loss: 0.0017 - AIF_loss: 0.0059 - val_loss: 0.0266 - val_Tissue_loss: 0.0018 - val_AIF_loss: 0.0247\n",
      "\n",
      "Epoch 00009: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0009.ckpt\n",
      "Epoch 10/200\n",
      "58408/58408 [==============================] - 276s 5ms/step - loss: 0.0074 - Tissue_loss: 0.0014 - AIF_loss: 0.0060 - val_loss: 0.0282 - val_Tissue_loss: 0.0018 - val_AIF_loss: 0.0262\n",
      "\n",
      "Epoch 00010: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0010.ckpt\n",
      "Epoch 11/200\n",
      "58408/58408 [==============================] - 273s 5ms/step - loss: 0.0071 - Tissue_loss: 0.0013 - AIF_loss: 0.0057 - val_loss: 0.0247 - val_Tissue_loss: 0.0019 - val_AIF_loss: 0.0225\n",
      "\n",
      "Epoch 00011: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0011.ckpt\n",
      "Epoch 12/200\n",
      "58408/58408 [==============================] - 272s 5ms/step - loss: 0.0071 - Tissue_loss: 0.0014 - AIF_loss: 0.0057 - val_loss: 0.0259 - val_Tissue_loss: 0.0018 - val_AIF_loss: 0.0240\n",
      "\n",
      "Epoch 00012: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0012.ckpt\n",
      "Epoch 13/200\n",
      "58408/58408 [==============================] - 275s 5ms/step - loss: 0.0072 - Tissue_loss: 0.0014 - AIF_loss: 0.0058 - val_loss: 0.0254 - val_Tissue_loss: 0.0035 - val_AIF_loss: 0.0216\n",
      "\n",
      "Epoch 00013: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0013.ckpt\n",
      "Epoch 14/200\n",
      "58408/58408 [==============================] - 281s 5ms/step - loss: 0.0071 - Tissue_loss: 0.0014 - AIF_loss: 0.0057 - val_loss: 0.0296 - val_Tissue_loss: 0.0035 - val_AIF_loss: 0.0256\n",
      "\n",
      "Epoch 00014: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0014.ckpt\n",
      "Epoch 15/200\n",
      "58408/58408 [==============================] - 285s 5ms/step - loss: 0.0071 - Tissue_loss: 0.0014 - AIF_loss: 0.0057 - val_loss: 0.0273 - val_Tissue_loss: 0.0021 - val_AIF_loss: 0.0251\n",
      "\n",
      "Epoch 00015: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0015.ckpt\n",
      "Epoch 16/200\n",
      "58408/58408 [==============================] - 279s 5ms/step - loss: 0.0072 - Tissue_loss: 0.0014 - AIF_loss: 0.0058 - val_loss: 0.0287 - val_Tissue_loss: 0.0020 - val_AIF_loss: 0.0266\n",
      "\n",
      "Epoch 00016: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0016.ckpt\n",
      "Epoch 17/200\n",
      "58408/58408 [==============================] - 275s 5ms/step - loss: 0.0070 - Tissue_loss: 0.0014 - AIF_loss: 0.0056 - val_loss: 0.0258 - val_Tissue_loss: 0.0025 - val_AIF_loss: 0.0231\n",
      "\n",
      "Epoch 00017: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0017.ckpt\n",
      "Epoch 18/200\n",
      "58408/58408 [==============================] - 274s 5ms/step - loss: 0.0069 - Tissue_loss: 0.0013 - AIF_loss: 0.0055 - val_loss: 0.0320 - val_Tissue_loss: 0.0023 - val_AIF_loss: 0.0292\n",
      "\n",
      "Epoch 00018: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0018.ckpt\n",
      "Epoch 19/200\n",
      "58408/58408 [==============================] - 274s 5ms/step - loss: 0.0056 - Tissue_loss: 0.0012 - AIF_loss: 0.0044 - val_loss: 0.0308 - val_Tissue_loss: 0.0022 - val_AIF_loss: 0.0285\n",
      "\n",
      "Epoch 00019: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0019.ckpt\n",
      "Epoch 20/200\n",
      "58408/58408 [==============================] - 278s 5ms/step - loss: 0.0056 - Tissue_loss: 0.0012 - AIF_loss: 0.0044 - val_loss: 0.0309 - val_Tissue_loss: 0.0021 - val_AIF_loss: 0.0287\n",
      "\n",
      "Epoch 00020: saving model to /hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp/T1W_ToftsModelFilt_l2-RES01-joint-mLossDC-len130-CV0-RoQ-XAIFinput-nopretrain/cp-0020.ckpt\n",
      "Epoch 21/200\n",
      "33813/58408 [================>.............] - ETA: 1:51 - loss: 0.0054 - Tissue_loss: 0.0012 - AIF_loss: 0.0042"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ----------- train model -----------\n",
    "# tensorboard callbck\n",
    "logdir = os.path.join(\"/hdd1/chaowei/dce-dl/log/T1W-XAIFinp\",prefix, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# save checkpoints\n",
    "checkpoint_path = os.path.join(\"/hdd1/chaowei/dce-dl/checkpoint/T1W-XAIFinp\",prefix,\"cp-{epoch:04d}.ckpt\")\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    period=CKPT_PERIOD)\n",
    "\n",
    "# adaptive learning rate\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=10, min_lr=0)\n",
    "\n",
    "if ISTRAIN is True:\n",
    "    history = model.fit(train_ds,epochs=N_EPOCHS,steps_per_epoch=N_STEPS,validation_data=valid_ds,\n",
    "                        callbacks = [reduce_lr, tensorboard_callback, cp_callback])\n",
    "\n",
    "\n",
    "    print(\"completed\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])\n",
    "\n",
    "if ISTRAIN is True:\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
